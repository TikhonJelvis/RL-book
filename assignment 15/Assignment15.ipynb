{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ReadMe**\n",
        "\n",
        "The question 1 is answered in part 1."
      ],
      "metadata": {
        "id": "9zY0nC5dRQZo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ7fOoXubGwK",
        "outputId": "f770c68d-5824-424b-d62f-a81807a21ae4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Winter 2022/CME241\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "%cd /content/drive/My\\ Drive/Winter\\ 2022/CME241"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r394i0lObkhY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from typing import Sequence, Tuple, Mapping\n",
        "\n",
        "S = str\n",
        "DataType = Sequence[Sequence[Tuple[S, float]]]\n",
        "ProbFunc = Mapping[S, Mapping[S, float]]\n",
        "RewardFunc = Mapping[S, float]\n",
        "ValueFunc = Mapping[S, float]\n",
        "\n",
        "\n",
        "def get_state_return_samples(\n",
        "    data: DataType\n",
        ") -> Sequence[Tuple[S, float]]:\n",
        "    \"\"\"\n",
        "    prepare sequence of (state, return) pairs.\n",
        "    Note: (state, return) pairs is not same as (state, reward) pairs.\n",
        "    \"\"\"\n",
        "    return [(s, sum(r for (_, r) in l[i:]))\n",
        "            for l in data for i, (s, _) in enumerate(l)]\n",
        "\n",
        "\n",
        "def get_mc_value_function(\n",
        "    state_return_samples: Sequence[Tuple[S, float]]\n",
        ") -> ValueFunc:\n",
        "    \"\"\"\n",
        "    Implement tabular MC Value Function compatible with the interface defined above.\n",
        "    \"\"\"\n",
        "\n",
        "    #Initialize container\n",
        "    TabularValueFunction: ValueFunc = defaultdict(float)\n",
        "    Count: Mapping[S, int] = defaultdict(int)\n",
        "\n",
        "    #Find sum\n",
        "    for state_return_sample in state_return_samples:\n",
        "      Count[state_return_sample[0]] += 1\n",
        "      TabularValueFunction[state_return_sample[0]] += state_return_sample[1]\n",
        "    \n",
        "    #Find average\n",
        "    for state in Count.keys():\n",
        "      TabularValueFunction[state] /= Count[state]\n",
        "\n",
        "    return TabularValueFunction\n",
        "\n",
        "\n",
        "def get_state_reward_next_state_samples(\n",
        "    data: DataType\n",
        ") -> Sequence[Tuple[S, float, S]]:\n",
        "    \"\"\"\n",
        "    prepare sequence of (state, reward, next_state) triples.\n",
        "    \"\"\"\n",
        "    return [(s, r, l[i+1][0] if i < len(l) - 1 else 'T')\n",
        "            for l in data for i, (s, r) in enumerate(l)]\n",
        "\n",
        "#Assume that srs means state reward state\n",
        "def get_probability_and_reward_functions(\n",
        "    srs_samples: Sequence[Tuple[S, float, S]]\n",
        ") -> Tuple[ProbFunc, RewardFunc]:\n",
        "    \"\"\"\n",
        "    Implement code that produces the probability transitions and the\n",
        "    reward function compatible with the interface defined above.\n",
        "    \"\"\"\n",
        "\n",
        "    #Initialize dict\n",
        "    Counts: Mapping[S, int] = defaultdict(int)\n",
        "    ProbFunct: ProbFunc = dict()\n",
        "    RewardFunct: RewardFunc = defaultdict(float)\n",
        "\n",
        "    for s, r, next_s in srs_samples:\n",
        "      #Create a dict in dict if have never seen s before\n",
        "      if not s in Counts.keys():\n",
        "        ProbFunct[s] = defaultdict(int) \n",
        "      Counts[s] += 1\n",
        "      ProbFunct[s][next_s] += 1 \n",
        "\n",
        "      RewardFunct[s] += r\n",
        "\n",
        "    for s in Counts.keys():\n",
        "      RewardFunct[s] /= Counts[s]\n",
        "      for next_s in ProbFunct[s].keys():\n",
        "        ProbFunct[s][next_s] /= Counts[s]\n",
        "\n",
        "    return tuple((ProbFunct, RewardFunct))  \n",
        "\n",
        "\n",
        "def get_mrp_value_function(\n",
        "    prob_func: ProbFunc,\n",
        "    reward_func: RewardFunc\n",
        ") -> ValueFunc:\n",
        "    \"\"\"\n",
        "    Implement code that calculates the MRP Value Function from the probability\n",
        "    transitions and reward function, compatible with the interface defined above.\n",
        "    Hint: Use the MRP Bellman Equation and simple linear algebra\n",
        "    \"\"\"\n",
        "\n",
        "    non_terminals = list(prob_func.keys())\n",
        "    rule = {state: i for i, state in enumerate(non_terminals)}\n",
        "    num_non_terminals = len(non_terminals)\n",
        "\n",
        "    #Convert into numpy array form\n",
        "    A = np.zeros((num_non_terminals,num_non_terminals))\n",
        "    r = np.zeros(num_non_terminals)\n",
        "\n",
        "    for state in non_terminals:\n",
        "      r[rule[state]] = reward_func[state]\n",
        "      for next_state in prob_func[state].keys():\n",
        "        if next_state in non_terminals:\n",
        "          A[rule[state]][rule[next_state]] = prob_func[state][next_state]\n",
        "\n",
        "    #We want to find v a (nontermial x 1) - matrix such that\n",
        "    # Av + r = v\n",
        "    # r = (I-A)v\n",
        "    # With regulariies condition,\n",
        "\n",
        "    v = np.linalg.inv(np.identity(num_non_terminals) - A) @ r\n",
        "\n",
        "    #Convert back to dictionary form\n",
        "    value_func: ValueFunc = dict()\n",
        "    for i in range(num_non_terminals):\n",
        "      value_func[non_terminals[i]] = v[i]\n",
        "\n",
        "    return value_func\n",
        "\n",
        "\n",
        "def get_td_value_function(\n",
        "    srs_samples: Sequence[Tuple[S, float, S]],\n",
        "    num_updates: int = 300000,\n",
        "    learning_rate: float = 0.3,\n",
        "    learning_rate_decay: int = 30\n",
        ") -> ValueFunc:\n",
        "    \"\"\"\n",
        "    Implement tabular TD(0) (with experience replay) Value Function compatible\n",
        "    with the interface defined above. Let the step size (alpha) be:\n",
        "    learning_rate * (updates / learning_rate_decay + 1) ** -0.5\n",
        "    so that Robbins-Monro condition is satisfied for the sequence of step sizes.\n",
        "    \"\"\"\n",
        "    #Initialize value function as being 0\n",
        "    value_func: ValueFunc = defaultdict(float)\n",
        "\n",
        "    num_samples = len(srs_samples)\n",
        "\n",
        "    for t in range(num_updates):\n",
        "\n",
        "      #Find learning rate\n",
        "      alpha = learning_rate * (t / learning_rate_decay + 1) ** -0.5\n",
        "\n",
        "      #Choose a sample randomly\n",
        "      s, r, next_s = srs_samples[np.random.randint(num_samples)]\n",
        "\n",
        "      #Expected\n",
        "      # r + value_func[next_s]\n",
        "      #What we have right now\n",
        "      # value_func[s]\n",
        "      #Discrepancy\n",
        "      # r + value_func[next_s] - value_func[s]\n",
        "      #Update\n",
        "      # value_func[s] = (1-alpha)*value_func[s] + alpha*(r + value_func[next_s] - value_func[s])\n",
        "\n",
        "      value_func[s] = (1-2*alpha)*value_func[s] + alpha*(r + value_func[next_s])\n",
        "\n",
        "    return value_func\n",
        "\n",
        "def get_lstd_value_function(\n",
        "    srs_samples: Sequence[Tuple[S, float, S]]\n",
        ") -> ValueFunc:\n",
        "    \"\"\"\n",
        "    Implement LSTD Value Function compatible with the interface defined above.\n",
        "    Hint: Tabular is a special case of linear function approx where each feature\n",
        "    is an indicator variables for a corresponding state and each parameter is\n",
        "    the value function for the corresponding state.\n",
        "    \"\"\"\n",
        "\n",
        "    non_terminal_states = list(set(s for s,_,_ in srs_samples))\n",
        "    rule = {state: i for i, state in enumerate(non_terminals)}\n",
        "    num_non_terminals = len(non_terminals)\n",
        "\n",
        "    #We expect V[s] = r + V[s']\n",
        "    #e_s - e_s' V = r\n",
        "\n",
        "    n = len(srs_samps)\n",
        "    A = np.zeros((n, num_non_terminals))\n",
        "    R = np.zeros(n)\n",
        "\n",
        "    for i, srs in enumerate(srs_samps):\n",
        "      s, r, s_next = srs\n",
        "      if s in non_terminals:\n",
        "        A[i,rule[s]] = 1\n",
        "      if s_next in non_terminals:\n",
        "        A[i,rule[s_next]] = -1\n",
        "      R[i] = r\n",
        "\n",
        "    #Use pseudo inverse\n",
        "    V = np.linalg.inv(A.T@A)@A.T@R\n",
        "\n",
        "    #Convert back to dictionary form\n",
        "    value_func: ValueFunc = dict()\n",
        "    for i in range(num_non_terminals):\n",
        "      value_func[non_terminals[i]] = v[i]\n",
        "\n",
        "    return value_func\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    given_data: DataType = [\n",
        "        [('A', 2.), ('A', 6.), ('B', 1.), ('B', 2.)],\n",
        "        [('A', 3.), ('B', 2.), ('A', 4.), ('B', 2.), ('B', 0.)],\n",
        "        [('B', 3.), ('B', 6.), ('A', 1.), ('B', 1.)],\n",
        "        [('A', 0.), ('B', 2.), ('A', 4.), ('B', 4.), ('B', 2.), ('B', 3.)],\n",
        "        [('B', 8.), ('B', 2.)]\n",
        "    ]\n",
        "\n",
        "    sr_samps = get_state_return_samples(given_data)\n",
        "\n",
        "    print(\"------------- MONTE CARLO VALUE FUNCTION --------------\")\n",
        "    print(get_mc_value_function(sr_samps))\n",
        "\n",
        "    srs_samps = get_state_reward_next_state_samples(given_data)\n",
        "\n",
        "    pfunc, rfunc = get_probability_and_reward_functions(srs_samps)\n",
        "    print(\"-------------- MRP VALUE FUNCTION ----------\")\n",
        "    print(get_mrp_value_function(pfunc, rfunc))\n",
        "\n",
        "    print(\"------------- TD VALUE FUNCTION --------------\")\n",
        "    print(get_td_value_function(srs_samps))\n",
        "\n",
        "    print(\"------------- LSTD VALUE FUNCTION --------------\")\n",
        "    print(get_lstd_value_function(srs_samps))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwpNn_QFkJRX",
        "outputId": "89d15a77-e934-4674-aaa9-38c7a1951016"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------- MONTE CARLO VALUE FUNCTION --------------\n",
            "defaultdict(<class 'float'>, {'A': 9.571428571428571, 'B': 5.642857142857143})\n",
            "-------------- MRP VALUE FUNCTION ----------\n",
            "{'A': 12.93333333333333, 'B': 9.599999999999998}\n",
            "------------- TD VALUE FUNCTION --------------\n",
            "defaultdict(<class 'float'>, {'B': 2.050786040602105, 'T': 0.0, 'A': 2.541605409072991})\n",
            "------------- LSTD VALUE FUNCTION --------------\n",
            "{'A': 12.93333333333333, 'B': 9.599999999999998}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Assignment15.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}